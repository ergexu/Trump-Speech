{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1b7c25-449d-4d01-9a20-27ae03a31be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://millercenter.org/the-presidency/presidential-speeches?field_president_target_id[8396]=8396'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "speeches = []\n",
    "transcripts = soup.findAll(\"div\", attrs={\"class\": \"views-field-title\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbcf1bc-3f9b-40f7-9c52-7f5df94fb729",
   "metadata": {},
   "source": [
    "Output directory for saving txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba38469-33ce-4254-9cf2-4ce78d1f55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'Trump_speech_txt_files'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i, transcript in enumerate(transcripts):\n",
    "    if i < 24:\n",
    "        link_url = transcript.find('a')['href']\n",
    "        link_response = requests.get(link_url)\n",
    "        link_html_content = link_response.content\n",
    "        link_soup = BeautifulSoup(link_html_content, 'html.parser')\n",
    "        link_text = link_soup.find(\"div\", attrs={'class': \"transcript-inner\"}).text.strip()\n",
    "        speeches.append(link_text)\n",
    "        SpeechTitle = transcript.text.strip()\n",
    "        URL = link_url\n",
    "        president = link_soup.find(\"p\", attrs={'class': \"president-name\"}).text.strip()\n",
    "        date = link_soup.find(\"p\", attrs={'class': \"episode-date\"}).text.strip()\n",
    "        summary = link_soup.find(\"div\", attrs={'class': \"about-sidebar--intro\"}).text.strip()\n",
    "\n",
    "        # Constructing the filename\n",
    "        filename = f\"{SpeechTitle}_{date.replace(' ', '_')}.txt\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Writing the transcript to the txt file\n",
    "        with open(filepath, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(link_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc96639-01f7-49d4-a331-0e34835f0a86",
   "metadata": {},
   "source": [
    "Load spaCy English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e8b35-07c4-4b4a-ab6f-11a991232fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696fd40-e5f6-463d-8767-f0a0f140050d",
   "metadata": {},
   "source": [
    "Input and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e62f993-6cf3-4f95-a3b9-8866281df46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'Trump_speech_txt_files'\n",
    "output_csv_path = 'annotated_corpus.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107110d9-5293-4c4c-96e6-b0e5758b6dd2",
   "metadata": {},
   "source": [
    "Create a list to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef9b7ab-523b-4a89-8896-84345e68c66a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892dc9b-8b02-4cbb-b705-4d7b38de6c91",
   "metadata": {},
   "source": [
    "Iterate through txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a48737-2155-4b9c-8a43-7c2a3f1ca5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "\n",
    "        # Read the content of the txt file\n",
    "        with open(filepath, 'r', encoding='utf-8') as txt_file:\n",
    "            document_text = txt_file.read()\n",
    "\n",
    "        # Use spaCy for tokenization, lemmatization, and POS tagging\n",
    "        doc = nlp(document_text)\n",
    "\n",
    "        # Extract tokens, lemmas, and POS tags\n",
    "        tokens = [token.text for token in doc]\n",
    "        lemmas = [token.lemma_ for token in doc]\n",
    "        pos_tags = [token.pos_ for token in doc]\n",
    "\n",
    "        # Extract title\n",
    "        title = filename.split(':')[-1].split('_')[0]\n",
    "\n",
    "        # Store the data in a dictionary\n",
    "        document_data = {\n",
    "            'Filename': filename,\n",
    "            'Title': title,\n",
    "            'Document': document_text,\n",
    "            'Noun': ' '.join([token.lemma_ for token in doc if token.pos_ == 'NOUN']),\n",
    "            'Tokens': tokens,\n",
    "            'Lemmas': lemmas,\n",
    "            'Parts-of-speech': pos_tags,\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the corpus_data list\n",
    "        corpus_data.append(document_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25609610-d39e-4371-aa7c-9e77c54f71d2",
   "metadata": {},
   "source": [
    "Convert the list of dictionaries to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a423b87-fd37-4bd5-bb42-32720f434068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_df = pd.DataFrame(corpus_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e07373-ee72-4713-a436-b23d503bb9f2",
   "metadata": {},
   "source": [
    "Save the annotated corpus as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cde18-3661-484d-9d0d-2d76a5ac35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.to_csv(output_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
